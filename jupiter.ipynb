{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key=\"sk-proj-FSQBRPkgskefsRAl24WrT3BlbkFJdcegXjvRj0qOGQ4lnZft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python es un lenguaje de programación de alto nivel, interpretado y multiparadigma. Fue creado en la década de 1990 por Guido van Rossum y se ha convertido en uno de los lenguajes de programación más populares y utilizados en la actualidad.\n",
      "\n",
      "Python se caracteriza por su sintaxis sencilla y legible, lo que lo hace ideal para principiantes en la programación. Además, es un lenguaje versátil que puede utilizarse para una amplia gama de aplicaciones, como desarrollo web, análisis de datos, inteligencia artificial, entre otros.\n",
      "\n",
      "Una de las ventajas de Python es su amplia biblioteca estándar, que ofrece herramientas y módulos predefinidos que facilitan el desarrollo de aplicaciones. También cuenta con una gran comunidad de desarrolladores que contribuyen con paquetes y recursos adicionales que pueden ser utilizados en proyectos.\n",
      "\n",
      "En resumen, Python es un lenguaje de programación poderoso, versátil y fácil de aprender, que ha ganado popularidad debido a su flexibilidad y facilidad de uso.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Explicame qué es python\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Explain me a {concept} in this language {language}.\"\n",
    ")\n",
    "\n",
    "PromptTemplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una función de activación en una red neuronal es una función matemática que se aplica a la salida de cada neurona en una capa de la red. Su propósito es introducir no linealidad en el modelo, permitiendo a la red aprender patrones más complejos y no simplemente realizar operaciones lineales.\n",
      "\n",
      "Existen diferentes tipos de funciones de activación, como la función sigmoide, la función ReLU (Rectified Linear Unit), la función tangente hiperbólica, entre otras. Cada una de estas funciones tiene sus propias características y ventajas para diferentes tipos de problemas.\n",
      "\n",
      "En resumen, la función de activación es fundamental en el funcionamiento de una red neuronal, ya que permite que la red pueda aprender de manera más efectiva y capturar patrones más complejos en los datos de entrada.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt_template.format(concept=\"activation function\", language=\"spanish\")).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "db_user = \"postgres\"\n",
    "db_pass = \"321321\"\n",
    "db_host = \"35.225.51.34\"\n",
    "db_port = 5432\n",
    "try:\n",
    "  connection = psycopg2.connect(\n",
    "      host=db_host,\n",
    "      port=db_port,\n",
    "      user=db_user,\n",
    "      password=db_pass\n",
    "  )\n",
    "  print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "  print(\"Connection failed:\", e)\n",
    "finally:\n",
    "  if connection:\n",
    "    connection.close()\n",
    "    print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "db_user = \"postgres\"\n",
    "db_pass = \"321321\"\n",
    "db_host = \"35.225.51.34\"\n",
    "db_port = 5432\n",
    "try:\n",
    "  connection = psycopg2.connect(\n",
    "      host=db_host,\n",
    "      port=db_port,\n",
    "      user=db_user,\n",
    "      password=db_pass\n",
    "  )\n",
    "  print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "  print(\"Connection failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(connection):\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS chatgpt_requests (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                usuario VARCHAR(255),\n",
    "                query TEXT,\n",
    "                response TEXT,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            );\n",
    "        \"\"\")\n",
    "        connection.commit()\n",
    "        print(\"Tables created successfully\")\n",
    "    except Exception as e:\n",
    "        print(\"Database table creation error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully\n"
     ]
    }
   ],
   "source": [
    "create_tables(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_database(usuario: str, query: str, response: str, connection):\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO chatgpt_requests (usuario, query, response)\n",
    "            VALUES (%s, %s, %s)\n",
    "        \"\"\", (usuario, query, response))\n",
    "        connection.commit()\n",
    "        print(\"Data saved to database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to database successfully\n"
     ]
    }
   ],
   "source": [
    "save_to_database(\"Nico\",\"hola chati\", \"prubando a ver que entra\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_database():\n",
    "    db_user = \"postgres\"\n",
    "    db_pass = \"321321\"\n",
    "    db_host = \"35.225.51.34\"\n",
    "    db_port = 5432\n",
    "        \n",
    "    try:\n",
    "\n",
    "        connection = psycopg2.connect(\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "            user=db_user,\n",
    "            password=db_pass\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Connection failed:\", e)\n",
    "        return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"sk-proj-FSQBRPkgskefsRAl24WrT3BlbkFJdcegXjvRj0qOGQ4lnZft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chatUsuario = \"Cual es el mejor seguro de vida a contratar?\"\n",
    "\n",
    "\n",
    "query = llm.invoke(f\"{chatUsuario}\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El mejor seguro de vida puede ofrecer una amplia gama de beneficios y características, como:\\n- Cobertura de por vida\\n- Flexibilidad en los pagos y beneficios\\n- Opciones de inversión\\n- Beneficios adicionales, como cobertura de enfermedades críticas o discapacidad\\n- Servicio al cliente de alta calidad\\n- Pólizas personalizadas según las necesidades y presupuesto del asegurado\\n- Solidez financiera y reputación sólida en el mercado de seguros.\\n\\nEs importante comparar diferentes opciones de seguros de vida y considerar las necesidades específicas de cada persona para encontrar la mejor cobertura. Se recomienda hablar con un agente de seguros de confianza para obtener asesoramiento personalizado.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Serializable.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m chatUsuario \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCual es el mejor seguro de vida a contratar?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Construct the insurance prompt using PromptTemplate\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m insurance_prompt_template \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43;03m    **Experto en seguros:**\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;43;03m    Soy Chat, un gran modelo de lenguaje capacitado para ser informativo y comprensivo. También estoy bien versado en el ámbito de los seguros.\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;43;03m    \u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;43;03m    Aquí está tu consulta: {chatUsuario}\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;43;03m    Proporcione una respuesta integral e informativa, basándose en su conocimiento de los conceptos y mejores prácticas de seguros.\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Format the template with the query\u001b[39;00m\n\u001b[0;32m     18\u001b[0m insurance_prompt \u001b[38;5;241m=\u001b[39m insurance_prompt_template\u001b[38;5;241m.\u001b[39mrender(query\u001b[38;5;241m=\u001b[39mquery)\n",
      "\u001b[1;31mTypeError\u001b[0m: Serializable.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define your query variable here\n",
    "chatUsuario = \"Cual es el mejor seguro de vida a contratar?\"\n",
    "\n",
    "# Construct the insurance prompt using PromptTemplate\n",
    "insurance_prompt_template = PromptTemplate(\n",
    "    \"\"\"\n",
    "    **Experto en seguros:**\n",
    "    Soy Chat, un gran modelo de lenguaje capacitado para ser informativo y comprensivo. También estoy bien versado en el ámbito de los seguros.\n",
    "    \n",
    "    Aquí está tu consulta: {chatUsuario}\n",
    "    Proporcione una respuesta integral e informativa, basándose en su conocimiento de los conceptos y mejores prácticas de seguros.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Format the template with the query\n",
    "insurance_prompt = insurance_prompt_template.render(query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling OpenAI API or saving to database: Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "nombre = \"nico\"\n",
    "\n",
    "chatUsuario\n",
    "usuario = f\"{nombre}\"\n",
    "\n",
    "if not connection:\n",
    "\n",
    "    {\"error\": \"Failed to connect to database\"}\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    respuesta = llm.invoke([{\"role\": \"system\", \"content\": f\"\"\"**Experto en seguros:**\n",
    "                                            Soy Chat, un gran modelo de lenguaje capacitado para ser informativo y comprensivo. También estoy bien versado en el ámbito de los seguros. Aquí está tu consulta:{chatUsuario} Proporcione una respuesta integral e informativa, basándose en su conocimiento de los conceptos y mejores prácticas de seguros.\n",
    "                                            \"\"\"}]).content\n",
    "\n",
    "    \n",
    "    chatgpt_response = respuesta\n",
    "\n",
    "    save_to_database(usuario, query, chatgpt_response, connection)\n",
    "    print({\"response\": chatgpt_response})\n",
    "except Exception as e:\n",
    "    print(\"Error calling OpenAI API or saving to database:\", e)\n",
    "    {\"error\": \"An error occurred. Please try again later.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El mejor seguro de vida a contratar dependerá de tus necesidades específicas, tu situación financiera y tus objetivos a largo plazo. Aquí te proporciono una guía general para ayudarte a elegir el seguro de vida adecuado:\\n\\n1. **Seguro de vida a término (term life insurance):** Este tipo de seguro de vida proporciona cobertura por un período específico de tiempo, como 10, 20 o 30 años. Es una opción popular para cubrir necesidades a corto plazo, como la hipoteca, la educación de los hijos o los gastos diarios. Suele ser más económico que otros tipos de seguros de vida.\\n\\n2. **Seguro de vida entera (whole life insurance):** Proporciona cobertura de por vida y suele tener un componente de valor en efectivo que crece con el tiempo. Es una opción a largo plazo que puede servir como una inversión adicional, pero también tiende a ser más costoso que el seguro a término.\\n\\n3. **Seguro de vida universal (universal life insurance):** Combina la protección del seguro de vida con la acumulación de valor en efectivo y ofrece más flexibilidad en términos de pagos de primas y ajustes de cobertura. Es una opción versátil que puede adaptarse a tus necesidades cambiantes.\\n\\nAl elegir un seguro de vida, es importante considerar factores como la cantidad de cobertura que necesitas, tu presupuesto, tus metas financieras a largo plazo y cualquier otra consideración personal. Además, es recomendable revisar y comparar las opciones de diferentes compañías de seguros para encontrar la mejor oferta en términos de cobertura y costos.\\n\\nRecuerda que el seguro de vida es una herramienta importante para proteger a tus seres queridos en caso de fallecimiento, por lo que es fundamental tomar una decisión informada y adaptada a tus circunstancias individuales. Si tienes dudas o necesitas asesoramiento personalizado, te recomiendo hablar con un agente de seguros o un asesor financiero para obtener orientación específica según tu situación.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Cual es el mejor seguro de vida a contratar?\"\n",
    "llm.invoke([{\"role\": \"system\", \"content\": f\"\"\"**Experto en seguros:**\n",
    "                                            Soy Chat, un gran modelo de lenguaje capacitado para ser informativo y comprensivo. También estoy bien versado en el ámbito de los seguros. Aquí está tu consulta:{query} Proporcione una respuesta integral e informativa, basándose en su conocimiento de los conceptos y mejores prácticas de seguros.\n",
    "                                            \"\"\"}]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Define el rol del usuario en el prompt\n",
    "prompt_usuario = {\"role\": \"user\", \"content\": prompt_template.format(pregunta=pregunta_usuario)}\n",
    "\n",
    "    # Realiza la llamada al modelo de lenguaje con el prompt completo\n",
    "respuesta = llm.invoke([{\"role\": \"system\", \"content\": \"\"\"Eres un especialista en cine.\n",
    "                                                        Puedes dar críticas de las películas o series que te pregunten,\n",
    "                                                        y recomendar películas o series a partir de un género, temática, plataforma, actor o director.\n",
    "                                                        Entiendes los títulos de películas y series en su idioma original, o los títulos en su versión de España.\n",
    "                                                        Si te solicitan otra cosa responde amablemente que no puedes ayudarles, y sugiere que te pregunten por cine.\n",
    "                                                        Termina tu respuesta despidiéndote, pero nunca hagas una pregunta al despedirte\"\"\"}, prompt_usuario])\n",
    "print(\"Respuesta del modelo:\", respuesta.content)\n",
    "    # Devuelve la respuesta generada por el modelo\n",
    "return respuesta.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexion BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Form, HTTPException, Depends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_history(connection, limit: int = 10):\n",
    "    \n",
    "    connection = psycopg2.connect(\n",
    "      host=db_host,\n",
    "      port=db_port,\n",
    "      user=db_user,\n",
    "      password=db_pass)\n",
    "    if not connection:\n",
    "        raise HTTPException(status_code=500, detail=\"Internal server error\")\n",
    "    else:\n",
    "\n",
    "        try:\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT user, query, response, created_at\n",
    "                FROM chatgpt_requests\n",
    "                ORDER BY created_at DESC\n",
    "                LIMIT %s\n",
    "            \"\"\", (limit,))\n",
    "            history = cursor.fetchall()\n",
    "            return [{\"user\": user, \"query\": query, \"response\": response, \"created_at\": created_at.strftime(\"%Y-%m-%d %H:%M:%S\")} for user, query, response, created_at in history]\n",
    "        except Exception as e:\n",
    "            print(\"Error fetching chat history:\", e)\n",
    "            raise HTTPException(status_code=500, detail=\"Internal server error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('postgres', 'hola chati', 'prubando a ver que entra', datetime.datetime(2024, 5, 13, 7, 17, 54, 79937))]\n"
     ]
    }
   ],
   "source": [
    "limit = 10\n",
    "connection = psycopg2.connect(\n",
    "      host=db_host,\n",
    "      port=db_port,\n",
    "      user=db_user,\n",
    "      password=db_pass\n",
    "  )\n",
    "try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT user, query, response, created_at\n",
    "            FROM chatgpt_requests\n",
    "            ORDER BY created_at DESC\n",
    "            LIMIT %s\n",
    "        \"\"\", (limit,))\n",
    "        history = cursor.fetchall()\n",
    "        [{\"user\": user, \"query\": query, \"response\": response, \"created_at\": created_at.strftime(\"%Y-%m-%d %H:%M:%S\")} for user, query, response, created_at in history]\n",
    "        print(history)\n",
    "except Exception as e:\n",
    "        print(\"Error fetching chat history:\", e)\n",
    "        raise HTTPException(status_code=500, detail=\"Internal server error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
